{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0069f8-e4c2-463f-9ab7-847745f9b0f0",
   "metadata": {},
   "source": [
    "# Titanic Model V3 - Stacking\n",
    "Build a Stacking Classifier ensemble to combine base models with a meta-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eae119-dad4-45b2-be22-55ba883d843a",
   "metadata": {},
   "source": [
    "## Section 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300b65b0-5ab3-42bb-bb2c-c20d3677c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588dcec-0522-48a1-ba65-ec64fcf34e05",
   "metadata": {},
   "source": [
    "## Section 2: Load Data and Feature Engineering (reuse V3 logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b67f5e70-80f7-492b-a3c1-be92c5188839",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# Feature Engineering\n",
    "def extract_title(df):\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title_Grouped'] = df['Title'].replace({\n",
    "        'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
    "        'Lady': 'Rare', 'Countess': 'Rare', 'Capt': 'Rare',\n",
    "        'Col': 'Rare', 'Don': 'Rare', 'Dr': 'Rare', 'Major': 'Rare',\n",
    "        'Rev': 'Rare', 'Sir': 'Rare', 'Jonkheer': 'Rare', 'Dona': 'Rare'\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def add_family_features(df):\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "    return df\n",
    "\n",
    "def engineer_features(df):\n",
    "    df = extract_title(df)\n",
    "    df = add_family_features(df)\n",
    "    return df\n",
    "\n",
    "train = engineer_features(train)\n",
    "test = engineer_features(test)\n",
    "\n",
    "# Impute Age\n",
    "title_age_medians = train.groupby('Title_Grouped')['Age'].median()\n",
    "\n",
    "def impute_age(df):\n",
    "    df['Age'] = df.apply(\n",
    "        lambda row: title_age_medians[row['Title_Grouped']] if pd.isnull(row['Age']) else row['Age'], axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "train = impute_age(train)\n",
    "test = impute_age(test)\n",
    "\n",
    "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "\n",
    "# Select Features\n",
    "features = [\n",
    "    'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
    "    'Title_Grouped', 'FamilySize', 'IsAlone', 'FarePerPerson'\n",
    "]\n",
    "\n",
    "X = train[features]\n",
    "y = train['Survived']\n",
    "X_test_final = test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2686ff-6e05-4d48-b074-8a73e21ffb88",
   "metadata": {},
   "source": [
    "## Section 3: Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd8edd26-6a4d-4625-9370-8d2135aa55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Age', 'Fare', 'FamilySize', 'FarePerPerson']\n",
    "categorical_features = ['Pclass', 'Sex', 'Title_Grouped', 'IsAlone']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceae11a-14e9-4a7a-86a1-19a5f939c3b8",
   "metadata": {},
   "source": [
    "## Section 4: Define and Build StackingClassifier Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14aecf82-1cd8-4a7b-a859-286dfe806fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_clf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', StackingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "            ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)),\n",
    "            ('xgb', XGBClassifier(eval_metric='logloss', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9176e29-f9b8-4ace-9e30-3287a3e2f18b",
   "metadata": {},
   "source": [
    "## Section 5: Cross-Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b43533-8677-4f33-baff-06f05dd3ecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy: 0.8271 ± 0.0243\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(stacking_clf, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation Accuracy: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3464ee7-c9bd-4aab-bca4-9e97ff11f63d",
   "metadata": {},
   "source": [
    "## Section 6: Train on Full Data and Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6243c6af-41c6-4692-9284-5be6f092e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission saved as: ../output/titanic_submission_v3-c_stacking_ensemble_2025-07-31.csv\n"
     ]
    }
   ],
   "source": [
    "stacking_clf.fit(X, y)\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': stacking_clf.predict(X_test_final)\n",
    "})\n",
    "filename = f\"../output/titanic_submission_v3-c_stacking_ensemble_2025-07-31.csv\"\n",
    "submission.to_csv(filename, index=False)\n",
    "print(f\"✅ Submission saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ed4da-70a8-415a-ac9b-cea149be1770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
